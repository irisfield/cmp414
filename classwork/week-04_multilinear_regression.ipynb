{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ch00226855/CMP414765Fall2022/blob/main/Week04_MultilinearRegression_Completed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXhaotNQxr2w"
   },
   "source": [
    "# Week 4\n",
    "# Multilinear Regression\n",
    "\n",
    "Last time we looked at a simple linear regression model $sales = \\beta_0 + \\beta_1\\cdot\\textit{TV advertising budget}$. More generally, a linear model makes a prediction by computing a weighted sum of their input features (plus a constant).\n",
    "\n",
    "**Reading: Chapter 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81lHyTpwx0zu"
   },
   "source": [
    "## Multilinear Regression: Model Assumptions\n",
    "**Model**:\n",
    "\n",
    "$\\hat{y} = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 +\\cdots + \\theta_nx_n$\n",
    "1. $\\hat{y}$ is the predicted value.\n",
    "2. $n$ is the number of features.\n",
    "3. $x_i$ is the i-th feature value.\n",
    "4. $\\theta_i$ is the i-th model parameter (associated with $x_i$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "azLxHqqUx02U"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Set print format on floating point numbers\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "cb5RGmIdx04v",
    "outputId": "05ae840e-644a-4db5-935f-3d68534b13f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Homework</th>\n",
       "      <th>Midterm</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clare</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eve</th>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Homework  Midterm  Final\n",
       "Alice        95       90     93\n",
       "Bob          70       60     66\n",
       "Clare        80       80     85\n",
       "David       100       80     60\n",
       "Eve          70       85     90"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toy example\n",
    "# columns = ['Homework', 'Midterm', 'Final']\n",
    "data = pd.DataFrame({\n",
    "    \"Homework\": [95, 70, 80, 100, 70],\n",
    "    \"Midterm\": [90, 60, 80, 80, 85],\n",
    "    \"Final\": [93, 66, 85, 60, 90]\n",
    "}, index=[\"Alice\", \"Bob\", \"Clare\", \"David\", \"Eve\"])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKguV_HWx09V"
   },
   "source": [
    "In this case:\n",
    "- $x_1$ is the homework feature\n",
    "- $x_2$ is the midterm feature\n",
    "- $y$ is the final score\n",
    "- model is: $final = \\theta_0 + \\theta_1 * homework + \\theta_2 * midterm$\n",
    "- We need to come up with values for $\\theta_0, \\theta_1, \\theta_2$ to complete the model.\n",
    "\n",
    "**Objective**: Suppose that another student Fred has Homework score 85 and Midterm score 80. What is prediction of his final exam score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txFgiEHAx0_q"
   },
   "source": [
    "## Multilinear Regression: Vectorized form\n",
    "\n",
    "The multilinear model can also be written as:\n",
    "\n",
    "**$\\hat{y} = \\theta\\cdot\\textbf{x}$**.\n",
    "1. $\\theta = (\\theta_0, \\theta_1, ..., \\theta_n)$ is the paramter vector.\n",
    "2. $\\textbf{x} = (1, x_1, ..., x_n)$ is the feature vector.\n",
    "3. The symbol $\\cdot$ represents the inner-product of two vectors. For example, $(1, 2, 3)\\cdot (4, 5, 6) = 1\\times 4 + 2\\times 5 + 3\\times 6 = 32$.\n",
    "\n",
    "**Why is the expression $\\theta\\cdot\\textbf{x}$ equivalent to $\\theta_0 + \\theta_1x_1 + \\theta_2x_2 +\\cdots + \\theta_nx_n$?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B8Acxyvfx1CF",
    "outputId": "75a8f2cf-4417-45e2-a7a3-b975a24c48f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's apply the linear regression tool in sci-kit learn on the toy example\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(data[[\"Homework\", \"Midterm\"]], data['Final']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDjZUNlDU3Na",
    "outputId": "94c90087-14d3-454f-bda8-558416e4ee6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([78.67442])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the prediction of Fred's final score?\n",
    "\n",
    "# Create a dataframe with Fred's records\n",
    "fred = pd.DataFrame([[85, 80]], columns=[\"Homework\", \"Midterm\"], index=['Fred'])\n",
    "fred\n",
    "model.predict(fred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "YyYsA6EhWWK6",
    "outputId": "b4958391-27e4-4ff9-baa7-844ecfec0c7a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Homework</th>\n",
       "      <th>Midterm</th>\n",
       "      <th>Final</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>84.581395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>63.279070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clare</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>85</td>\n",
       "      <td>82.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>67.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eve</th>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>90</td>\n",
       "      <td>95.953488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Homework  Midterm  Final  Prediction\n",
       "Alice        95       90     93   84.581395\n",
       "Bob          70       60     66   63.279070\n",
       "Clare        80       80     85   82.255814\n",
       "David       100       80     60   67.930233\n",
       "Eve          70       85     90   95.953488"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model's prediction is 78. This looks safe. But how much variation the prediction has?\n",
    "# We can use model's error on the training data seems pretty good,\n",
    "# but how well does it do on new data?\n",
    "\n",
    "data['Prediction'] = model.predict(data[['Homework', 'Midterm']])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoD9GMG1x1Em",
    "outputId": "9096d1c2-2d95-4f21-8d8e-9bb791890a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta1, theta2: [-0.71628 1.30698]\n",
      "theta0: 35.00000000000003\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the estimated parameter values.\n",
    "print(\"theta1, theta2:\", model.coef_)\n",
    "print(\"theta0:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAYjx93CYPeN"
   },
   "source": [
    "Now, let's create a linear model that describes the relationship between `sales` and all three ways of advertising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "yaLpN0AeYeMS",
    "outputId": "137bcba1-5995-47b7-8c36-d0aeb2f47e40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.statlearning.com/s/Advertising.csv\"\n",
    "advertising = pd.read_csv(url, index_col=0)\n",
    "advertising.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLp0zCnOY9wn"
   },
   "source": [
    "Proposed model: $sales = \\theta_0 + \\theta_1\\cdot TV + \\theta_2\\cdot radio + \\theta_3\\cdot newspaper$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeQewBGYisak"
   },
   "source": [
    "In order to effectively evalution the model's performance on new data, we need to split the data set into a **training set** and a **test set**. The model will be training with the training set only, and therefore the test set can be considered as new data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0u0JR6wZrwS",
    "outputId": "96cddc69-d4d2-468f-9812-19972b027ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 4)\n",
      "(20, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_set, test_set = train_test_split(advertising, test_size=0.1) # a good test size is 10% - 30%\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "N64-Qfn8xWyp"
   },
   "outputs": [],
   "source": [
    "# train_test_split can split more than one data set\n",
    "input = advertising[['TV', 'radio', 'newspaper']]\n",
    "# input.head()\n",
    "output = advertising[['sales']]\n",
    "# output.head()\n",
    "input_train, input_test, output_train, output_test = train_test_split(input, output, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQjZLVzNYg4Q",
    "outputId": "f180e67f-f5d0-4b5b-bb0f-13d350601ddd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ex: Build a linear regression model named \"model2\" on the training set.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model2 = LinearRegression()\n",
    "model2.fit(training_set[['TV', 'radio', 'newspaper']], training_set['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhAe5dXQaNtT",
    "outputId": "8e244249-3cc3-4ea8-e8f6-f0ae5a168023"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8768864012803057 0.04600403147445695 0.19133675892693483 -0.002305170946470897\n",
      "Mean squared error: 2.0230535671876586\n"
     ]
    }
   ],
   "source": [
    "# Ex: Calculate the MSE of model2 on the test set\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Find the coefficients of the model\n",
    "theta1, theta2, theta3 = model2.coef_\n",
    "theta0 = model2.intercept_\n",
    "print(theta0, theta1, theta2, theta3)\n",
    "\n",
    "# Find the model's prediction on each test record\n",
    "test_set['Prediction'] = theta1 * test_set['TV'] + theta2 * test_set['radio'] \\\n",
    "            + theta3 * test_set['newspaper'] + theta0\n",
    "\n",
    "test_set.head()\n",
    "\n",
    "# Calculate the MSE\n",
    "MSE = mean_squared_error(test_set['sales'], test_set['Prediction'])\n",
    "print(\"Mean squared error:\", MSE)\n",
    "\n",
    "# Compare this MSE with the MSE from last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2h2FrEs2eK0",
    "outputId": "2f4da91c-d9d3-475e-c10a-1b8eb18981da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 2.0230535671876586\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, we can use the model's predict() method to obtain the predictions\n",
    "from sklearn.metrics import mean_squared_error\n",
    "test_set['Prediction'] = model2.predict(test_set[['TV', 'radio', 'newspaper']])\n",
    "# test_set.head()\n",
    "\n",
    "MSE = mean_squared_error(test_set['sales'], test_set['Prediction'])\n",
    "print(\"Mean squared error:\", MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwJG44-7x1HE"
   },
   "source": [
    "## Multilinear Regression: Cost Function\n",
    "In order to calculate the best value for each parameter, we need a **cost function** that evaluates the errors made by a give set of parameter values. Here we use the **mean squared error (MSE)** function as the cost function:\n",
    "\n",
    "$J(\\textbf{X}, \\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\big(\\theta\\cdot\\textbf{x}^{(i)} - y^{(i)}\\big)^2$\n",
    "\n",
    "Here $(\\textbf{x}^{(i)}, y^{(i)})$ represents the i-th training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uh-Zy_vEx1JZ",
    "outputId": "73c8e756-10be-4094-94bb-9766d5771a0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.82790697674421\n"
     ]
    }
   ],
   "source": [
    "# Ex: Calculate the MSE cost of the toy example for the parameter values given by sci-kit learn.\n",
    "\n",
    "# theta1, theta2 = model.coef_\n",
    "# theta0 = model.intercept_\n",
    "# print(theta0, theta1, theta2)\n",
    "\n",
    "predictions = model.predict(data[['Homework', 'Midterm']])\n",
    "# print(predictions)\n",
    "MSE = mean_squared_error(data['Final'], predictions)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZG2rW2SNx1Lw"
   },
   "source": [
    "## Multilinear Regression: Training Algorithm 1\n",
    "The value of $\\theta$ that minimizes the cost function is given by the following **normal equation**:\n",
    "\n",
    "$\\hat{\\theta} = \\big(\\textbf{X}^T\\cdot\\textbf{X}\\big)^{-1}\\cdot\\textbf{X}^T\\cdot\\textbf{y}$.\n",
    "\n",
    "1. $\\textbf{X}$ is an $m\\times (n+1)$ matrix whose i-th row is $\\textbf{x}^{(i)}$.\n",
    "$$\\textbf{X} = \\begin{pmatrix}\n",
    "1 & x^{(1)}_1 & x^{(1)}_2 & \\cdots & x^{(1)}_n \\\\\n",
    "1 & x^{(2)}_1 & x^{(2)}_2 & \\cdots & x^{(2)}_n \\\\\n",
    "\\vdots & \\vdots &\\vdots & \\ddots & \\vdots \\\\\n",
    "1 & x^{(m)}_1 & x^{(m)}_2 & \\cdots & x^{(m)}_n \\\\\n",
    "\\end{pmatrix}$$\n",
    "2. $$\\textbf{y} = \\begin{pmatrix}y^{(1)} \\\\ \\vdots \\\\ y^{(m)}\\end{pmatrix}$$.\n",
    "3. The cost function $J(\\theta)$ also has a matrix expression\n",
    "$$J(\\theta) = \\frac{1}{m}(\\textbf{X}\\cdot\\theta - \\textbf{y})^T\\cdot (\\textbf{X}\\cdot\\theta - \\textbf{y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M0r86Sigx1OO",
    "outputId": "f4f2244f-f8a2-415a-d3b4-5b3b2e8ce52b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 4)\n"
     ]
    }
   ],
   "source": [
    "# Ex: Construct matrix X using DataFrame.values, np.hstack(), np.ones()\n",
    "# training_set.head()\n",
    "X1 = np.ones([len(training_set), 1])\n",
    "# print(X1)\n",
    "X2 = training_set[['TV', 'radio', 'newspaper']].values\n",
    "# print(X2)\n",
    "X = np.hstack([X1, X2])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bIZZCIicx1Q7",
    "outputId": "71d83002-c0c5-4379-9c08-9c18fc6470f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 1)\n"
     ]
    }
   ],
   "source": [
    "# Ex: Construct vector y\n",
    "y = training_set[['sales']].values\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "197CDh19x1Th",
    "outputId": "bcc3379f-efc3-4262-9302-5e1862b7581b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.87689]\n",
      " [0.04600]\n",
      " [0.19134]\n",
      " [-0.00231]]\n"
     ]
    }
   ],
   "source": [
    "# Apply the normal equation to find theta\n",
    "theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SnpLfMkulFm5",
    "outputId": "6ac75453-45e1-45e3-83dc-95e55156d9f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04600 0.19134 -0.00231]\n",
      "2.8768864012803057\n"
     ]
    }
   ],
   "source": [
    "# The results should be the same as the sklearn model\n",
    "print(model2.coef_)\n",
    "print(model2.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ezXjZlvx1WG"
   },
   "source": [
    "## Multilinear Regression: Training Algorithm 2\n",
    "The normal equation is not applicable when $\\textbf{X}^T\\cdot\\textbf{X}$ is not invertible. It happens if:\n",
    "- Several features are linearly dependent (for example, feature3 = feature1 + feature2)\n",
    "- The number of features is greater than the number of training data (for example, DNA data)\n",
    "\n",
    "When the matrix $\\textbf{X}$ is too large, the normal equation may take too long to finish since it requires a matrix multiplication.\n",
    "\n",
    "In these cases, we can use the **gradient descent** method to minimize the cost function instead.\n",
    "\n",
    "Gradient descent with one variable ideally looks like this:\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/0*fU8XFt-NCMZGAWND.\" width=\"600\">\n",
    "\n",
    "Gradient descent with two variables ideally looks like this:\n",
    "<img src=\"https://blog.paperspace.com/content/images/2019/09/F1-02.large.jpg\" width=\"600\">\n",
    "\n",
    "Gradient descent is an iterative algorithm for finding the **local minimum** of a differentiable function.\n",
    "- Choose an initial value of $\\hat{\\theta}$ and a **learning rate** $r$.\n",
    "- For each iteration $k$, do:\n",
    "  - Calculate the partial derivative of the cost function:\n",
    "$$\n",
    "\\frac{\\partial J(\\hat{\\theta})}{\\partial \\theta} = \\frac{2}{m}\\cdot\\textbf{X}^T\\cdot(\\textbf{X}\\cdot\\theta - \\textbf{y}).\n",
    "$$\n",
    "  - Update the parameter vector:\n",
    "  $$\\hat{\\theta} \\leftarrow \\hat{\\theta} - r\\cdot\\frac{\\partial J(\\hat{\\theta})}{\\partial \\theta}.$$\n",
    "\n",
    "- **Verify the formula of partial derivative assuming there is one input feature.**\n",
    "\n",
    "- End iteration if certain stop criteria is reached, such as:\n",
    "    - Value of $\\hat{\\theta}$ becomes stable.\n",
    "    - Certain iteration amount is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "clRpPwu-x1Yp"
   },
   "outputs": [],
   "source": [
    "# Choose an initial value for each parameter.\n",
    "theta = np.array([[3.00],\n",
    "                  [0.05],\n",
    "                  [0.20],\n",
    "                  [0.00]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "fVKaYafgkrCa"
   },
   "outputs": [],
   "source": [
    "# Construct matrix X and y\n",
    "N = training_set.shape[0]\n",
    "\n",
    "col1 = np.ones([N, 1])\n",
    "col234 = training_set[['TV', 'radio', 'newspaper']].values\n",
    "X = np.hstack([col1, col234])\n",
    "\n",
    "y = training_set[['sales']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "irpo2zsSsO-W",
    "outputId": "33a5858c-d577-42be-cbbd-93aa921e9618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial cost: [[2.87321]]\n"
     ]
    }
   ],
   "source": [
    "def MSE_cost(theta, X, y):\n",
    "    m = X.shape[0]\n",
    "    M = X.dot(theta) - y\n",
    "    return 1/m * M.T.dot(M)\n",
    "\n",
    "print(\"Initial cost:\", MSE_cost(theta, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yP5gFqHx1bM",
    "outputId": "5aa06437-b179-4a5b-c088-b853db542bd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient: \n",
      " [[0.03527]\n",
      " [-0.00015]\n",
      " [0.00099]\n",
      " [-0.00096]]\n",
      "Theta: \n",
      " [[2.99915]\n",
      " [0.04567]\n",
      " [0.19001]\n",
      " [-0.00304]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.87321]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform gradient descent once.\n",
    "# Choose a learning rate r\n",
    "r = 1e-5 # r = 0.00001\n",
    "\n",
    "# 1. Calculate the gradient\n",
    "m = len(training_set)\n",
    "gradient = 2/m * X.T.dot(X.dot(theta) - y)\n",
    "print(\"Gradient: \\n\", gradient)\n",
    "\n",
    "# 2. Update the parameters\n",
    "theta = theta - r * gradient\n",
    "print(\"Theta: \\n\", theta)\n",
    "\n",
    "\n",
    "# 3. (optional) Show the MSE cost with new parameter values\n",
    "MSE_cost(theta, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPqDCTznx1dq",
    "outputId": "0aa96d56-b9e7-4124-9d7f-2de4154640bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Gradient:\n",
      " [[1.99522]\n",
      " [359.41169]\n",
      " [52.26402]\n",
      " [66.26656]]\n",
      "New theta:\n",
      " [[2.99998]\n",
      " [0.04641]\n",
      " [0.19948]\n",
      " [-0.00066]]\n",
      "New cost: [[3.07382]]\n",
      "Iteration: 100\n",
      "Gradient:\n",
      " [[0.06717]\n",
      " [-0.45790]\n",
      " [2.54879]\n",
      " [0.86331]]\n",
      "New theta:\n",
      " [[2.99987]\n",
      " [0.04526]\n",
      " [0.19490]\n",
      " [-0.00435]]\n",
      "New cost: [[2.87897]]\n",
      "Iteration: 200\n",
      "Gradient:\n",
      " [[0.04763]\n",
      " [-0.11789]\n",
      " [1.29377]\n",
      " [-0.26988]]\n",
      "New theta:\n",
      " [[2.99981]\n",
      " [0.04551]\n",
      " [0.19309]\n",
      " [-0.00446]]\n",
      "New cost: [[2.87543]]\n",
      "Iteration: 300\n",
      "Gradient:\n",
      " [[0.04197]\n",
      " [-0.04310]\n",
      " [0.80244]\n",
      " [-0.35327]]\n",
      "New theta:\n",
      " [[2.99977]\n",
      " [0.04558]\n",
      " [0.19208]\n",
      " [-0.00412]]\n",
      "New cost: [[2.87425]]\n",
      "Iteration: 400\n",
      "Gradient:\n",
      " [[0.03957]\n",
      " [-0.02237]\n",
      " [0.53591]\n",
      " [-0.27595]]\n",
      "New theta:\n",
      " [[2.99973]\n",
      " [0.04561]\n",
      " [0.19142]\n",
      " [-0.00381]]\n",
      "New cost: [[2.87371]]\n",
      "Iteration: 500\n",
      "Gradient:\n",
      " [[0.03820]\n",
      " [-0.01403]\n",
      " [0.36608]\n",
      " [-0.19658]]\n",
      "New theta:\n",
      " [[2.99969]\n",
      " [0.04563]\n",
      " [0.19098]\n",
      " [-0.00357]]\n",
      "New cost: [[2.87346]]\n",
      "Iteration: 600\n",
      "Gradient:\n",
      " [[0.03731]\n",
      " [-0.00943]\n",
      " [0.25167]\n",
      " [-0.13682]]\n",
      "New theta:\n",
      " [[2.99965]\n",
      " [0.04564]\n",
      " [0.19067]\n",
      " [-0.00341]]\n",
      "New cost: [[2.87333]]\n",
      "Iteration: 700\n",
      "Gradient:\n",
      " [[0.03671]\n",
      " [-0.00648]\n",
      " [0.17329]\n",
      " [-0.09465]]\n",
      "New theta:\n",
      " [[2.99962]\n",
      " [0.04565]\n",
      " [0.19046]\n",
      " [-0.00329]]\n",
      "New cost: [[2.87328]]\n",
      "Iteration: 800\n",
      "Gradient:\n",
      " [[0.03629]\n",
      " [-0.00449]\n",
      " [0.11935]\n",
      " [-0.06537]]\n",
      "New theta:\n",
      " [[2.99958]\n",
      " [0.04565]\n",
      " [0.19032]\n",
      " [-0.00321]]\n",
      "New cost: [[2.87325]]\n",
      "Iteration: 900\n",
      "Gradient:\n",
      " [[0.03600]\n",
      " [-0.00312]\n",
      " [0.08217]\n",
      " [-0.04515]]\n",
      "New theta:\n",
      " [[2.99954]\n",
      " [0.04566]\n",
      " [0.19022]\n",
      " [-0.00316]]\n",
      "New cost: [[2.87323]]\n",
      "Iteration: 1000\n",
      "Gradient:\n",
      " [[0.03579]\n",
      " [-0.00218]\n",
      " [0.05654]\n",
      " [-0.03120]]\n",
      "New theta:\n",
      " [[2.99951]\n",
      " [0.04566]\n",
      " [0.19015]\n",
      " [-0.00312]]\n",
      "New cost: [[2.87323]]\n",
      "Iteration: 1100\n",
      "Gradient:\n",
      " [[0.03565]\n",
      " [-0.00154]\n",
      " [0.03887]\n",
      " [-0.02158]]\n",
      "New theta:\n",
      " [[2.99947]\n",
      " [0.04566]\n",
      " [0.19010]\n",
      " [-0.00309]]\n",
      "New cost: [[2.87322]]\n",
      "Iteration: 1200\n",
      "Gradient:\n",
      " [[0.03555]\n",
      " [-0.00109]\n",
      " [0.02668]\n",
      " [-0.01495]]\n",
      "New theta:\n",
      " [[2.99944]\n",
      " [0.04566]\n",
      " [0.19007]\n",
      " [-0.00308]]\n",
      "New cost: [[2.87322]]\n",
      "Iteration: 1300\n",
      "Gradient:\n",
      " [[0.03547]\n",
      " [-0.00078]\n",
      " [0.01828]\n",
      " [-0.01037]]\n",
      "New theta:\n",
      " [[2.99940]\n",
      " [0.04566]\n",
      " [0.19005]\n",
      " [-0.00306]]\n",
      "New cost: [[2.87322]]\n",
      "Iteration: 1400\n",
      "Gradient:\n",
      " [[0.03542]\n",
      " [-0.00057]\n",
      " [0.01249]\n",
      " [-0.00722]]\n",
      "New theta:\n",
      " [[2.99937]\n",
      " [0.04566]\n",
      " [0.19003]\n",
      " [-0.00306]]\n",
      "New cost: [[2.87322]]\n",
      "Iteration: 1500\n",
      "Gradient:\n",
      " [[0.03538]\n",
      " [-0.00042]\n",
      " [0.00849]\n",
      " [-0.00504]]\n",
      "New theta:\n",
      " [[2.99933]\n",
      " [0.04566]\n",
      " [0.19002]\n",
      " [-0.00305]]\n",
      "New cost: [[2.87321]]\n",
      "Iteration: 1600\n",
      "Gradient:\n",
      " [[0.03535]\n",
      " [-0.00032]\n",
      " [0.00573]\n",
      " [-0.00354]]\n",
      "New theta:\n",
      " [[2.99929]\n",
      " [0.04567]\n",
      " [0.19002]\n",
      " [-0.00305]]\n",
      "New cost: [[2.87321]]\n",
      "Iteration: 1700\n",
      "Gradient:\n",
      " [[0.03532]\n",
      " [-0.00025]\n",
      " [0.00383]\n",
      " [-0.00251]]\n",
      "New theta:\n",
      " [[2.99926]\n",
      " [0.04567]\n",
      " [0.19001]\n",
      " [-0.00304]]\n",
      "New cost: [[2.87321]]\n",
      "Iteration: 1800\n",
      "Gradient:\n",
      " [[0.03530]\n",
      " [-0.00020]\n",
      " [0.00252]\n",
      " [-0.00179]]\n",
      "New theta:\n",
      " [[2.99922]\n",
      " [0.04567]\n",
      " [0.19001]\n",
      " [-0.00304]]\n",
      "New cost: [[2.87321]]\n",
      "Iteration: 1900\n",
      "Gradient:\n",
      " [[0.03529]\n",
      " [-0.00017]\n",
      " [0.00162]\n",
      " [-0.00130]]\n",
      "New theta:\n",
      " [[2.99919]\n",
      " [0.04567]\n",
      " [0.19001]\n",
      " [-0.00304]]\n",
      "New cost: [[2.87321]]\n"
     ]
    }
   ],
   "source": [
    "# Perform gradient descent multiple times\n",
    "r = 1e-5\n",
    "\n",
    "theta = np.array([[3.00],\n",
    "                  [0.05],\n",
    "                  [0.20],\n",
    "                  [0.00]])\n",
    "\n",
    "# theta = np.array([[6.00],\n",
    "#                   [-0.10],\n",
    "#                   [-0.40],\n",
    "#                   [0.00]])\n",
    "\n",
    "MSEs = [] # store the intermediate MSEs\n",
    "num_iterations = 2000\n",
    "\n",
    "for i in range(num_iterations):\n",
    "\n",
    "    gradient = (2/m) * X.T.dot(X.dot(theta) - y)\n",
    "    theta = theta - r * gradient\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"Iteration:\", i)\n",
    "        print(\"Gradient:\\n\", gradient)\n",
    "        print(\"New theta:\\n\", theta)\n",
    "        MSE = MSE_cost(theta, X, y)\n",
    "        print(\"New cost:\", MSE)\n",
    "        MSEs.append(MSE[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "0sfCU6C33reK",
    "outputId": "9a9471e6-129d-4142-d78b-428d3c6462b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f48a3304220>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learning curve.\n",
    "\n",
    "plt.plot(range(len(MSEs)-2), MSEs[2:], 'b.--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXOFqVwlx1gQ"
   },
   "source": [
    "**Discussion**\n",
    "1. Change $r$ to 0.000001 and 0.01. Observe the MSE curve.\n",
    "2. Do the initial parameter values matter?\n",
    "3. How to determine when to stop the iteration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEnnJd4Qx1ii",
    "outputId": "d2111601-8f79-49c3-ee8e-71a1975afadf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.87689 0.04600 0.19134 -0.00231]\n",
      "2.8710513996748257\n"
     ]
    }
   ],
   "source": [
    "# As a comparison, let's calculate the MSE on the training set with optimal parameter values\n",
    "best_theta = np.hstack([model2.intercept_, model2.coef_, ])\n",
    "print(best_theta)\n",
    "\n",
    "predictions = model2.predict(training_set[['TV', 'radio', 'newspaper']])\n",
    "best_MSE = mean_squared_error(training_set['sales'], predictions)\n",
    "print(best_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVWfuoUHx1lB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVfSS1dgx1np"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
